{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import larq as lq\n",
    "import alexnet\n",
    "import binary_densenet\n",
    "import binary_densenet37_dilated\n",
    "import binary_resnet_e18\n",
    "import birealnet\n",
    "import quicknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+AlexNet stats--------------------------------------------------------------------------------------------------+\n",
      "| Layer                    Input prec.            Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                (bit)                          x 1       x 1     (kB)                          |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d_464                   -   (-1, 56, 56, 64)     23232         0     2.84           0     72855552 |\n",
      "| max_pooling2d_98                   -   (-1, 27, 27, 64)         0         0        0           0            0 |\n",
      "| batch_normalization_694            -   (-1, 27, 27, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_465                   1  (-1, 27, 27, 192)    307200         0    37.50   223948800            0 |\n",
      "| max_pooling2d_99                   -  (-1, 13, 13, 192)         0         0        0           0            0 |\n",
      "| batch_normalization_695            -  (-1, 13, 13, 192)         0       384     1.50           0            0 |\n",
      "| quant_conv2d_466                   1  (-1, 13, 13, 384)    663552         0    81.00   112140288            0 |\n",
      "| batch_normalization_696            -  (-1, 13, 13, 384)         0       768     3.00           0            0 |\n",
      "| quant_conv2d_467                   1  (-1, 13, 13, 384)   1327104         0   162.00   224280576            0 |\n",
      "| batch_normalization_697            -  (-1, 13, 13, 384)         0       768     3.00           0            0 |\n",
      "| quant_conv2d_468                   1  (-1, 13, 13, 256)    884736         0   108.00   149520384            0 |\n",
      "| max_pooling2d_100                  -    (-1, 6, 6, 256)         0         0        0           0            0 |\n",
      "| batch_normalization_698            -    (-1, 6, 6, 256)         0       512     2.00           0            0 |\n",
      "| flatten_54                         -         (-1, 9216)         0         0        0           0            0 |\n",
      "| quant_dense_12                     1         (-1, 4096)  37748736         0  4608.00    37748736            0 |\n",
      "| batch_normalization_699            -         (-1, 4096)         0      8192    32.00           0            0 |\n",
      "| quant_dense_13                     1         (-1, 4096)  16777216         0  2048.00    16777216            0 |\n",
      "| batch_normalization_700            -         (-1, 4096)         0      8192    32.00           0            0 |\n",
      "| quant_dense_14                     1         (-1, 1000)   4096000         0   500.00     4096000            0 |\n",
      "| batch_normalization_701            -         (-1, 1000)         0      2000     7.81           0            0 |\n",
      "| activation_95                      -         (-1, 1000)         0         0        0           ?            ? |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                    61827776     20944  7629.15   768512000     72855552 |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "+AlexNet summary-------------------------------+\n",
      "| Total params                      61.8 M     |\n",
      "| Trainable params                  61.8 M     |\n",
      "| Non-trainable params              20.9 k     |\n",
      "| Model size                        7.45 MiB   |\n",
      "| Model size (8-bit FP weights)     7.39 MiB   |\n",
      "| Float-32 Equivalent               235.93 MiB |\n",
      "| Compression Ratio of Memory       0.03       |\n",
      "| Number of MACs                    841 M      |\n",
      "| Ratio of MACs that are binarized  0.9134     |\n",
      "+----------------------------------------------+\n",
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+BiRealNet stats-------------------------------------------------------------------------------------------------+\n",
      "| Layer                    Input prec.             Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                (bit)                           x 1       x 1     (kB)                          |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "| conv2d_84                          -  (-1, 112, 112, 64)         0      9408    36.75           0    118013952 |\n",
      "| batch_normalization_722            -  (-1, 112, 112, 64)         0       128     0.50           0            0 |\n",
      "| max_pooling2d_102                  -    (-1, 56, 56, 64)         0         0        0           0            0 |\n",
      "| quant_conv2d_469                   1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_723            -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_470                   1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_724            -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_471                   1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_725            -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_472                   1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_726            -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_473                   1   (-1, 28, 28, 128)     73728         0     9.00    57802752            0 |\n",
      "| flatten_59                         -        (-1, 100352)         0         0        0           0            0 |\n",
      "| reshape_54                         -     (-1, 100352, 1)         0         0        0           ?            ? |\n",
      "| average_pooling1d_27               -      (-1, 50176, 1)         0         0        0           ?            ? |\n",
      "| reshape_55                         -    (-1, 28, 28, 64)         0         0        0           ?            ? |\n",
      "| conv2d_85                          -   (-1, 28, 28, 128)         0      8192    32.00           0      6422528 |\n",
      "| batch_normalization_727            -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| batch_normalization_728            -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_474                   1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_729            -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_475                   1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_730            -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_476                   1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_731            -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_477                   1   (-1, 14, 14, 256)    294912         0    36.00    57802752            0 |\n",
      "| flatten_60                         -         (-1, 50176)         0         0        0           0            0 |\n",
      "| reshape_56                         -      (-1, 50176, 1)         0         0        0           ?            ? |\n",
      "| average_pooling1d_28               -      (-1, 25088, 1)         0         0        0           ?            ? |\n",
      "| reshape_57                         -   (-1, 14, 14, 128)         0         0        0           ?            ? |\n",
      "| conv2d_86                          -   (-1, 14, 14, 256)         0     32768   128.00           0      6422528 |\n",
      "| batch_normalization_732            -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| batch_normalization_733            -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_478                   1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_734            -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_479                   1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_735            -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_480                   1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_736            -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_481                   1     (-1, 7, 7, 512)   1179648         0   144.00    57802752            0 |\n",
      "| flatten_61                         -         (-1, 25088)         0         0        0           0            0 |\n",
      "| reshape_58                         -      (-1, 25088, 1)         0         0        0           ?            ? |\n",
      "| average_pooling1d_29               -      (-1, 12544, 1)         0         0        0           ?            ? |\n",
      "| reshape_59                         -     (-1, 7, 7, 256)         0         0        0           ?            ? |\n",
      "| conv2d_87                          -     (-1, 7, 7, 512)         0    131072   512.00           0      6422528 |\n",
      "| batch_normalization_737            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| batch_normalization_738            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_482                   1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_739            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_483                   1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_740            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_484                   1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_741            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| average_pooling2d_10               -     (-1, 1, 1, 512)         0         0        0           0            0 |\n",
      "| flatten_62                         -           (-1, 512)         0         0        0           0            0 |\n",
      "| dense_21                           -          (-1, 1000)         0    513000  2003.91           0       512000 |\n",
      "| activation_97                      -          (-1, 1000)         0         0        0           ?            ? |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                     10985472    704040  4091.16  1676279808    137793536 |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "+BiRealNet summary----------------------------+\n",
      "| Total params                      11.7 M    |\n",
      "| Trainable params                  11.7 M    |\n",
      "| Non-trainable params              9.6 k     |\n",
      "| Model size                        4.00 MiB  |\n",
      "| Model size (8-bit FP weights)     1.98 MiB  |\n",
      "| Float-32 Equivalent               44.59 MiB |\n",
      "| Compression Ratio of Memory       0.09      |\n",
      "| Number of MACs                    1.81 B    |\n",
      "| Ratio of MACs that are binarized  0.9240    |\n",
      "+---------------------------------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+DenseNet_E28 stats-------------------------------------------------------------------------------------------------+\n",
      "| Layer                    Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                (bit)                              x 1       x 1     (kB)                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "| input_35                           -  ((None, 224, 224, 3),)        0         0        0           ?            ? |\n",
      "| conv2d_92                          -      (-1, 112, 112, 64)        0      9408    36.75           0    118013952 |\n",
      "| batch_normalization_770            -      (-1, 112, 112, 64)        0       128     0.50           0            0 |\n",
      "| activation_104                     -      (-1, 112, 112, 64)        0         0        0           ?            ? |\n",
      "| max_pooling2d_108                  -        (-1, 56, 56, 64)        0         0        0           0            0 |\n",
      "| batch_normalization_771            -        (-1, 56, 56, 64)        0       128     0.50           0            0 |\n",
      "| quant_conv2d_508                   1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n",
      "| concatenate_403                    -       (-1, 56, 56, 128)        0         0        0           ?            ? |\n",
      "| batch_normalization_772            -       (-1, 56, 56, 128)        0       256     1.00           0            0 |\n",
      "| quant_conv2d_509                   1        (-1, 56, 56, 64)    73728         0     9.00   231211008            0 |\n",
      "| concatenate_404                    -       (-1, 56, 56, 192)        0         0        0           ?            ? |\n",
      "| batch_normalization_773            -       (-1, 56, 56, 192)        0       384     1.50           0            0 |\n",
      "| quant_conv2d_510                   1        (-1, 56, 56, 64)   110592         0    13.50   346816512            0 |\n",
      "| concatenate_405                    -       (-1, 56, 56, 256)        0         0        0           ?            ? |\n",
      "| batch_normalization_774            -       (-1, 56, 56, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_511                   1        (-1, 56, 56, 64)   147456         0    18.00   462422016            0 |\n",
      "| concatenate_406                    -       (-1, 56, 56, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_775            -       (-1, 56, 56, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_512                   1        (-1, 56, 56, 64)   184320         0    22.50   578027520            0 |\n",
      "| concatenate_407                    -       (-1, 56, 56, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_776            -       (-1, 56, 56, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_513                   1        (-1, 56, 56, 64)   221184         0    27.00   693633024            0 |\n",
      "| concatenate_408                    -       (-1, 56, 56, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_777            -       (-1, 56, 56, 448)        0       896     3.50           0            0 |\n",
      "| max_pooling2d_109                  -       (-1, 28, 28, 448)        0         0        0           0            0 |\n",
      "| activation_105                     -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n",
      "| conv2d_93                          -       (-1, 28, 28, 160)        0     71680   280.00           0     56197120 |\n",
      "| batch_normalization_778            -       (-1, 28, 28, 160)        0       320     1.25           0            0 |\n",
      "| quant_conv2d_514                   1        (-1, 28, 28, 64)    92160         0    11.25    72253440            0 |\n",
      "| concatenate_409                    -       (-1, 28, 28, 224)        0         0        0           ?            ? |\n",
      "| batch_normalization_779            -       (-1, 28, 28, 224)        0       448     1.75           0            0 |\n",
      "| quant_conv2d_515                   1        (-1, 28, 28, 64)   129024         0    15.75   101154816            0 |\n",
      "| concatenate_410                    -       (-1, 28, 28, 288)        0         0        0           ?            ? |\n",
      "| batch_normalization_780            -       (-1, 28, 28, 288)        0       576     2.25           0            0 |\n",
      "| quant_conv2d_516                   1        (-1, 28, 28, 64)   165888         0    20.25   130056192            0 |\n",
      "| concatenate_411                    -       (-1, 28, 28, 352)        0         0        0           ?            ? |\n",
      "| batch_normalization_781            -       (-1, 28, 28, 352)        0       704     2.75           0            0 |\n",
      "| quant_conv2d_517                   1        (-1, 28, 28, 64)   202752         0    24.75   158957568            0 |\n",
      "| concatenate_412                    -       (-1, 28, 28, 416)        0         0        0           ?            ? |\n",
      "| batch_normalization_782            -       (-1, 28, 28, 416)        0       832     3.25           0            0 |\n",
      "| quant_conv2d_518                   1        (-1, 28, 28, 64)   239616         0    29.25   187858944            0 |\n",
      "| concatenate_413                    -       (-1, 28, 28, 480)        0         0        0           ?            ? |\n",
      "| batch_normalization_783            -       (-1, 28, 28, 480)        0       960     3.75           0            0 |\n",
      "| quant_conv2d_519                   1        (-1, 28, 28, 64)   276480         0    33.75   216760320            0 |\n",
      "| concatenate_414                    -       (-1, 28, 28, 544)        0         0        0           ?            ? |\n",
      "| batch_normalization_784            -       (-1, 28, 28, 544)        0      1088     4.25           0            0 |\n",
      "| max_pooling2d_110                  -       (-1, 14, 14, 544)        0         0        0           0            0 |\n",
      "| activation_106                     -       (-1, 14, 14, 544)        0         0        0           ?            ? |\n",
      "| conv2d_94                          -       (-1, 14, 14, 192)        0    104448   408.00           0     20471808 |\n",
      "| batch_normalization_785            -       (-1, 14, 14, 192)        0       384     1.50           0            0 |\n",
      "| quant_conv2d_520                   1        (-1, 14, 14, 64)   110592         0    13.50    21676032            0 |\n",
      "| concatenate_415                    -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n",
      "| batch_normalization_786            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_521                   1        (-1, 14, 14, 64)   147456         0    18.00    28901376            0 |\n",
      "| concatenate_416                    -       (-1, 14, 14, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_787            -       (-1, 14, 14, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_522                   1        (-1, 14, 14, 64)   184320         0    22.50    36126720            0 |\n",
      "| concatenate_417                    -       (-1, 14, 14, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_788            -       (-1, 14, 14, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_523                   1        (-1, 14, 14, 64)   221184         0    27.00    43352064            0 |\n",
      "| concatenate_418                    -       (-1, 14, 14, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_789            -       (-1, 14, 14, 448)        0       896     3.50           0            0 |\n",
      "| quant_conv2d_524                   1        (-1, 14, 14, 64)   258048         0    31.50    50577408            0 |\n",
      "| concatenate_419                    -       (-1, 14, 14, 512)        0         0        0           ?            ? |\n",
      "| batch_normalization_790            -       (-1, 14, 14, 512)        0      1024     4.00           0            0 |\n",
      "| quant_conv2d_525                   1        (-1, 14, 14, 64)   294912         0    36.00    57802752            0 |\n",
      "| concatenate_420                    -       (-1, 14, 14, 576)        0         0        0           ?            ? |\n",
      "| batch_normalization_791            -       (-1, 14, 14, 576)        0      1152     4.50           0            0 |\n",
      "| max_pooling2d_111                  -         (-1, 7, 7, 576)        0         0        0           0            0 |\n",
      "| activation_107                     -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n",
      "| conv2d_95                          -         (-1, 7, 7, 256)        0    147456   576.00           0      7225344 |\n",
      "| batch_normalization_792            -         (-1, 7, 7, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_526                   1          (-1, 7, 7, 64)   147456         0    18.00     7225344            0 |\n",
      "| concatenate_421                    -         (-1, 7, 7, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_793            -         (-1, 7, 7, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_527                   1          (-1, 7, 7, 64)   184320         0    22.50     9031680            0 |\n",
      "| concatenate_422                    -         (-1, 7, 7, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_794            -         (-1, 7, 7, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_528                   1          (-1, 7, 7, 64)   221184         0    27.00    10838016            0 |\n",
      "| concatenate_423                    -         (-1, 7, 7, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_795            -         (-1, 7, 7, 448)        0       896     3.50           0            0 |\n",
      "| quant_conv2d_529                   1          (-1, 7, 7, 64)   258048         0    31.50    12644352            0 |\n",
      "| concatenate_424                    -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n",
      "| batch_normalization_796            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |\n",
      "| quant_conv2d_530                   1          (-1, 7, 7, 64)   294912         0    36.00    14450688            0 |\n",
      "| concatenate_425                    -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n",
      "| batch_normalization_797            -         (-1, 7, 7, 576)        0      1152     4.50           0            0 |\n",
      "| activation_108                     -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n",
      "| max_pooling2d_112                  -         (-1, 1, 1, 576)        0         0        0           0            0 |\n",
      "| flatten_64                         -               (-1, 576)        0         0        0           0            0 |\n",
      "| dense_23                           -              (-1, 1000)        0    577000  2253.91           0       576000 |\n",
      "| activation_109                     -              (-1, 1000)        0         0        0           ?            ? |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                         4202496    929000  4141.91  3587383296    202484224 |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "+DenseNet_E28 summary-------------------------+\n",
      "| Total params                      5.13 M    |\n",
      "| Trainable params                  5.11 M    |\n",
      "| Non-trainable params              19 k      |\n",
      "| Model size                        4.04 MiB  |\n",
      "| Model size (8-bit FP weights)     1.39 MiB  |\n",
      "| Float-32 Equivalent               19.58 MiB |\n",
      "| Compression Ratio of Memory       0.21      |\n",
      "| Number of MACs                    3.79 B    |\n",
      "| Ratio of MACs that are binarized  0.9466    |\n",
      "+---------------------------------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+DenseNet_E37 stats-------------------------------------------------------------------------------------------------+\n",
      "| Layer                    Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                (bit)                              x 1       x 1     (kB)                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "| input_37                           -  ((None, 224, 224, 3),)        0         0        0           ?            ? |\n",
      "| conv2d_100                         -      (-1, 112, 112, 64)        0      9408    36.75           0    118013952 |\n",
      "| batch_normalization_835            -      (-1, 112, 112, 64)        0       128     0.50           0            0 |\n",
      "| activation_116                     -      (-1, 112, 112, 64)        0         0        0           ?            ? |\n",
      "| max_pooling2d_118                  -        (-1, 56, 56, 64)        0         0        0           0            0 |\n",
      "| batch_normalization_836            -        (-1, 56, 56, 64)        0       128     0.50           0            0 |\n",
      "| quant_conv2d_563                   1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n",
      "| concatenate_458                    -       (-1, 56, 56, 128)        0         0        0           ?            ? |\n",
      "| batch_normalization_837            -       (-1, 56, 56, 128)        0       256     1.00           0            0 |\n",
      "| quant_conv2d_564                   1        (-1, 56, 56, 64)    73728         0     9.00   231211008            0 |\n",
      "| concatenate_459                    -       (-1, 56, 56, 192)        0         0        0           ?            ? |\n",
      "| batch_normalization_838            -       (-1, 56, 56, 192)        0       384     1.50           0            0 |\n",
      "| quant_conv2d_565                   1        (-1, 56, 56, 64)   110592         0    13.50   346816512            0 |\n",
      "| concatenate_460                    -       (-1, 56, 56, 256)        0         0        0           ?            ? |\n",
      "| batch_normalization_839            -       (-1, 56, 56, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_566                   1        (-1, 56, 56, 64)   147456         0    18.00   462422016            0 |\n",
      "| concatenate_461                    -       (-1, 56, 56, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_840            -       (-1, 56, 56, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_567                   1        (-1, 56, 56, 64)   184320         0    22.50   578027520            0 |\n",
      "| concatenate_462                    -       (-1, 56, 56, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_841            -       (-1, 56, 56, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_568                   1        (-1, 56, 56, 64)   221184         0    27.00   693633024            0 |\n",
      "| concatenate_463                    -       (-1, 56, 56, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_842            -       (-1, 56, 56, 448)        0       896     3.50           0            0 |\n",
      "| max_pooling2d_119                  -       (-1, 28, 28, 448)        0         0        0           0            0 |\n",
      "| activation_117                     -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n",
      "| conv2d_101                         -       (-1, 28, 28, 128)        0     57344   224.00           0     44957696 |\n",
      "| batch_normalization_843            -       (-1, 28, 28, 128)        0       256     1.00           0            0 |\n",
      "| quant_conv2d_569                   1        (-1, 28, 28, 64)    73728         0     9.00    57802752            0 |\n",
      "| concatenate_464                    -       (-1, 28, 28, 192)        0         0        0           ?            ? |\n",
      "| batch_normalization_844            -       (-1, 28, 28, 192)        0       384     1.50           0            0 |\n",
      "| quant_conv2d_570                   1        (-1, 28, 28, 64)   110592         0    13.50    86704128            0 |\n",
      "| concatenate_465                    -       (-1, 28, 28, 256)        0         0        0           ?            ? |\n",
      "| batch_normalization_845            -       (-1, 28, 28, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_571                   1        (-1, 28, 28, 64)   147456         0    18.00   115605504            0 |\n",
      "| concatenate_466                    -       (-1, 28, 28, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_846            -       (-1, 28, 28, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_572                   1        (-1, 28, 28, 64)   184320         0    22.50   144506880            0 |\n",
      "| concatenate_467                    -       (-1, 28, 28, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_847            -       (-1, 28, 28, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_573                   1        (-1, 28, 28, 64)   221184         0    27.00   173408256            0 |\n",
      "| concatenate_468                    -       (-1, 28, 28, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_848            -       (-1, 28, 28, 448)        0       896     3.50           0            0 |\n",
      "| quant_conv2d_574                   1        (-1, 28, 28, 64)   258048         0    31.50   202309632            0 |\n",
      "| concatenate_469                    -       (-1, 28, 28, 512)        0         0        0           ?            ? |\n",
      "| batch_normalization_849            -       (-1, 28, 28, 512)        0      1024     4.00           0            0 |\n",
      "| quant_conv2d_575                   1        (-1, 28, 28, 64)   294912         0    36.00   231211008            0 |\n",
      "| concatenate_470                    -       (-1, 28, 28, 576)        0         0        0           ?            ? |\n",
      "| batch_normalization_850            -       (-1, 28, 28, 576)        0      1152     4.50           0            0 |\n",
      "| quant_conv2d_576                   1        (-1, 28, 28, 64)   331776         0    40.50   260112384            0 |\n",
      "| concatenate_471                    -       (-1, 28, 28, 640)        0         0        0           ?            ? |\n",
      "| batch_normalization_851            -       (-1, 28, 28, 640)        0      1280     5.00           0            0 |\n",
      "| max_pooling2d_120                  -       (-1, 14, 14, 640)        0         0        0           0            0 |\n",
      "| activation_118                     -       (-1, 14, 14, 640)        0         0        0           ?            ? |\n",
      "| conv2d_102                         -       (-1, 14, 14, 192)        0    122880   480.00           0     24084480 |\n",
      "| batch_normalization_852            -       (-1, 14, 14, 192)        0       384     1.50           0            0 |\n",
      "| quant_conv2d_577                   1        (-1, 14, 14, 64)   110592         0    13.50    21676032            0 |\n",
      "| concatenate_472                    -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n",
      "| batch_normalization_853            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_578                   1        (-1, 14, 14, 64)   147456         0    18.00    28901376            0 |\n",
      "| concatenate_473                    -       (-1, 14, 14, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_854            -       (-1, 14, 14, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_579                   1        (-1, 14, 14, 64)   184320         0    22.50    36126720            0 |\n",
      "| concatenate_474                    -       (-1, 14, 14, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_855            -       (-1, 14, 14, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_580                   1        (-1, 14, 14, 64)   221184         0    27.00    43352064            0 |\n",
      "| concatenate_475                    -       (-1, 14, 14, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_856            -       (-1, 14, 14, 448)        0       896     3.50           0            0 |\n",
      "| quant_conv2d_581                   1        (-1, 14, 14, 64)   258048         0    31.50    50577408            0 |\n",
      "| concatenate_476                    -       (-1, 14, 14, 512)        0         0        0           ?            ? |\n",
      "| batch_normalization_857            -       (-1, 14, 14, 512)        0      1024     4.00           0            0 |\n",
      "| quant_conv2d_582                   1        (-1, 14, 14, 64)   294912         0    36.00    57802752            0 |\n",
      "| concatenate_477                    -       (-1, 14, 14, 576)        0         0        0           ?            ? |\n",
      "| batch_normalization_858            -       (-1, 14, 14, 576)        0      1152     4.50           0            0 |\n",
      "| quant_conv2d_583                   1        (-1, 14, 14, 64)   331776         0    40.50    65028096            0 |\n",
      "| concatenate_478                    -       (-1, 14, 14, 640)        0         0        0           ?            ? |\n",
      "| batch_normalization_859            -       (-1, 14, 14, 640)        0      1280     5.00           0            0 |\n",
      "| quant_conv2d_584                   1        (-1, 14, 14, 64)   368640         0    45.00    72253440            0 |\n",
      "| concatenate_479                    -       (-1, 14, 14, 704)        0         0        0           ?            ? |\n",
      "| batch_normalization_860            -       (-1, 14, 14, 704)        0      1408     5.50           0            0 |\n",
      "| quant_conv2d_585                   1        (-1, 14, 14, 64)   405504         0    49.50    79478784            0 |\n",
      "| concatenate_480                    -       (-1, 14, 14, 768)        0         0        0           ?            ? |\n",
      "| batch_normalization_861            -       (-1, 14, 14, 768)        0      1536     6.00           0            0 |\n",
      "| quant_conv2d_586                   1        (-1, 14, 14, 64)   442368         0    54.00    86704128            0 |\n",
      "| concatenate_481                    -       (-1, 14, 14, 832)        0         0        0           ?            ? |\n",
      "| batch_normalization_862            -       (-1, 14, 14, 832)        0      1664     6.50           0            0 |\n",
      "| quant_conv2d_587                   1        (-1, 14, 14, 64)   479232         0    58.50    93929472            0 |\n",
      "| concatenate_482                    -       (-1, 14, 14, 896)        0         0        0           ?            ? |\n",
      "| batch_normalization_863            -       (-1, 14, 14, 896)        0      1792     7.00           0            0 |\n",
      "| quant_conv2d_588                   1        (-1, 14, 14, 64)   516096         0    63.00   101154816            0 |\n",
      "| concatenate_483                    -       (-1, 14, 14, 960)        0         0        0           ?            ? |\n",
      "| batch_normalization_864            -       (-1, 14, 14, 960)        0      1920     7.50           0            0 |\n",
      "| max_pooling2d_121                  -         (-1, 7, 7, 960)        0         0        0           0            0 |\n",
      "| activation_119                     -         (-1, 7, 7, 960)        0         0        0           ?            ? |\n",
      "| conv2d_103                         -         (-1, 7, 7, 256)        0    245760   960.00           0     12042240 |\n",
      "| batch_normalization_865            -         (-1, 7, 7, 256)        0       512     2.00           0            0 |\n",
      "| quant_conv2d_589                   1          (-1, 7, 7, 64)   147456         0    18.00     7225344            0 |\n",
      "| concatenate_484                    -         (-1, 7, 7, 320)        0         0        0           ?            ? |\n",
      "| batch_normalization_866            -         (-1, 7, 7, 320)        0       640     2.50           0            0 |\n",
      "| quant_conv2d_590                   1          (-1, 7, 7, 64)   184320         0    22.50     9031680            0 |\n",
      "| concatenate_485                    -         (-1, 7, 7, 384)        0         0        0           ?            ? |\n",
      "| batch_normalization_867            -         (-1, 7, 7, 384)        0       768     3.00           0            0 |\n",
      "| quant_conv2d_591                   1          (-1, 7, 7, 64)   221184         0    27.00    10838016            0 |\n",
      "| concatenate_486                    -         (-1, 7, 7, 448)        0         0        0           ?            ? |\n",
      "| batch_normalization_868            -         (-1, 7, 7, 448)        0       896     3.50           0            0 |\n",
      "| quant_conv2d_592                   1          (-1, 7, 7, 64)   258048         0    31.50    12644352            0 |\n",
      "| concatenate_487                    -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n",
      "| batch_normalization_869            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |\n",
      "| quant_conv2d_593                   1          (-1, 7, 7, 64)   294912         0    36.00    14450688            0 |\n",
      "| concatenate_488                    -         (-1, 7, 7, 576)        0         0        0           ?            ? |\n",
      "| batch_normalization_870            -         (-1, 7, 7, 576)        0      1152     4.50           0            0 |\n",
      "| quant_conv2d_594                   1          (-1, 7, 7, 64)   331776         0    40.50    16257024            0 |\n",
      "| concatenate_489                    -         (-1, 7, 7, 640)        0         0        0           ?            ? |\n",
      "| batch_normalization_871            -         (-1, 7, 7, 640)        0      1280     5.00           0            0 |\n",
      "| activation_120                     -         (-1, 7, 7, 640)        0         0        0           ?            ? |\n",
      "| max_pooling2d_122                  -         (-1, 1, 1, 640)        0         0        0           0            0 |\n",
      "| flatten_66                         -               (-1, 640)        0         0        0           0            0 |\n",
      "| dense_25                           -              (-1, 1000)        0    641000  2503.91           0       640000 |\n",
      "| activation_121                     -              (-1, 1000)        0         0        0           ?            ? |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                         7593984   1108264  5256.16  4506808320    199738368 |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "+DenseNet_E37 summary-------------------------+\n",
      "| Total params                      8.7 M     |\n",
      "| Trainable params                  8.67 M    |\n",
      "| Non-trainable params              31.9 k    |\n",
      "| Model size                        5.13 MiB  |\n",
      "| Model size (8-bit FP weights)     1.96 MiB  |\n",
      "| Float-32 Equivalent               33.20 MiB |\n",
      "| Compression Ratio of Memory       0.15      |\n",
      "| Number of MACs                    4.71 B    |\n",
      "| Ratio of MACs that are binarized  0.9576    |\n",
      "+---------------------------------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+DenseNet_E45 stats--------------------------------------------------------------------------------------------------+\n",
      "| Layer                    Input prec.                 Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                (bit)                               x 1       x 1     (kB)                          |\n",
      "+--------------------------------------------------------------------------------------------------------------------+\n",
      "| input_39                           -  ((None, 224, 224, 3),)         0         0        0           ?            ? |\n",
      "| conv2d_108                         -      (-1, 112, 112, 64)         0      9408    36.75           0    118013952 |\n",
      "| batch_normalization_917            -      (-1, 112, 112, 64)         0       128     0.50           0            0 |\n",
      "| activation_128                     -      (-1, 112, 112, 64)         0         0        0           ?            ? |\n",
      "| max_pooling2d_128                  -        (-1, 56, 56, 64)         0         0        0           0            0 |\n",
      "| batch_normalization_918            -        (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_635                   1        (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| concatenate_530                    -       (-1, 56, 56, 128)         0         0        0           ?            ? |\n",
      "| batch_normalization_919            -       (-1, 56, 56, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_636                   1        (-1, 56, 56, 64)     73728         0     9.00   231211008            0 |\n",
      "| concatenate_531                    -       (-1, 56, 56, 192)         0         0        0           ?            ? |\n",
      "| batch_normalization_920            -       (-1, 56, 56, 192)         0       384     1.50           0            0 |\n",
      "| quant_conv2d_637                   1        (-1, 56, 56, 64)    110592         0    13.50   346816512            0 |\n",
      "| concatenate_532                    -       (-1, 56, 56, 256)         0         0        0           ?            ? |\n",
      "| batch_normalization_921            -       (-1, 56, 56, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_638                   1        (-1, 56, 56, 64)    147456         0    18.00   462422016            0 |\n",
      "| concatenate_533                    -       (-1, 56, 56, 320)         0         0        0           ?            ? |\n",
      "| batch_normalization_922            -       (-1, 56, 56, 320)         0       640     2.50           0            0 |\n",
      "| quant_conv2d_639                   1        (-1, 56, 56, 64)    184320         0    22.50   578027520            0 |\n",
      "| concatenate_534                    -       (-1, 56, 56, 384)         0         0        0           ?            ? |\n",
      "| batch_normalization_923            -       (-1, 56, 56, 384)         0       768     3.00           0            0 |\n",
      "| quant_conv2d_640                   1        (-1, 56, 56, 64)    221184         0    27.00   693633024            0 |\n",
      "| concatenate_535                    -       (-1, 56, 56, 448)         0         0        0           ?            ? |\n",
      "| batch_normalization_924            -       (-1, 56, 56, 448)         0       896     3.50           0            0 |\n",
      "| max_pooling2d_129                  -       (-1, 28, 28, 448)         0         0        0           0            0 |\n",
      "| activation_129                     -       (-1, 28, 28, 448)         0         0        0           ?            ? |\n",
      "| conv2d_109                         -       (-1, 28, 28, 160)         0     71680   280.00           0     56197120 |\n",
      "| batch_normalization_925            -       (-1, 28, 28, 160)         0       320     1.25           0            0 |\n",
      "| quant_conv2d_641                   1        (-1, 28, 28, 64)     92160         0    11.25    72253440            0 |\n",
      "| concatenate_536                    -       (-1, 28, 28, 224)         0         0        0           ?            ? |\n",
      "| batch_normalization_926            -       (-1, 28, 28, 224)         0       448     1.75           0            0 |\n",
      "| quant_conv2d_642                   1        (-1, 28, 28, 64)    129024         0    15.75   101154816            0 |\n",
      "| concatenate_537                    -       (-1, 28, 28, 288)         0         0        0           ?            ? |\n",
      "| batch_normalization_927            -       (-1, 28, 28, 288)         0       576     2.25           0            0 |\n",
      "| quant_conv2d_643                   1        (-1, 28, 28, 64)    165888         0    20.25   130056192            0 |\n",
      "| concatenate_538                    -       (-1, 28, 28, 352)         0         0        0           ?            ? |\n",
      "| batch_normalization_928            -       (-1, 28, 28, 352)         0       704     2.75           0            0 |\n",
      "| quant_conv2d_644                   1        (-1, 28, 28, 64)    202752         0    24.75   158957568            0 |\n",
      "| concatenate_539                    -       (-1, 28, 28, 416)         0         0        0           ?            ? |\n",
      "| batch_normalization_929            -       (-1, 28, 28, 416)         0       832     3.25           0            0 |\n",
      "| quant_conv2d_645                   1        (-1, 28, 28, 64)    239616         0    29.25   187858944            0 |\n",
      "| concatenate_540                    -       (-1, 28, 28, 480)         0         0        0           ?            ? |\n",
      "| batch_normalization_930            -       (-1, 28, 28, 480)         0       960     3.75           0            0 |\n",
      "| quant_conv2d_646                   1        (-1, 28, 28, 64)    276480         0    33.75   216760320            0 |\n",
      "| concatenate_541                    -       (-1, 28, 28, 544)         0         0        0           ?            ? |\n",
      "| batch_normalization_931            -       (-1, 28, 28, 544)         0      1088     4.25           0            0 |\n",
      "| quant_conv2d_647                   1        (-1, 28, 28, 64)    313344         0    38.25   245661696            0 |\n",
      "| concatenate_542                    -       (-1, 28, 28, 608)         0         0        0           ?            ? |\n",
      "| batch_normalization_932            -       (-1, 28, 28, 608)         0      1216     4.75           0            0 |\n",
      "| quant_conv2d_648                   1        (-1, 28, 28, 64)    350208         0    42.75   274563072            0 |\n",
      "| concatenate_543                    -       (-1, 28, 28, 672)         0         0        0           ?            ? |\n",
      "| batch_normalization_933            -       (-1, 28, 28, 672)         0      1344     5.25           0            0 |\n",
      "| quant_conv2d_649                   1        (-1, 28, 28, 64)    387072         0    47.25   303464448            0 |\n",
      "| concatenate_544                    -       (-1, 28, 28, 736)         0         0        0           ?            ? |\n",
      "| batch_normalization_934            -       (-1, 28, 28, 736)         0      1472     5.75           0            0 |\n",
      "| quant_conv2d_650                   1        (-1, 28, 28, 64)    423936         0    51.75   332365824            0 |\n",
      "| concatenate_545                    -       (-1, 28, 28, 800)         0         0        0           ?            ? |\n",
      "| batch_normalization_935            -       (-1, 28, 28, 800)         0      1600     6.25           0            0 |\n",
      "| quant_conv2d_651                   1        (-1, 28, 28, 64)    460800         0    56.25   361267200            0 |\n",
      "| concatenate_546                    -       (-1, 28, 28, 864)         0         0        0           ?            ? |\n",
      "| batch_normalization_936            -       (-1, 28, 28, 864)         0      1728     6.75           0            0 |\n",
      "| quant_conv2d_652                   1        (-1, 28, 28, 64)    497664         0    60.75   390168576            0 |\n",
      "| concatenate_547                    -       (-1, 28, 28, 928)         0         0        0           ?            ? |\n",
      "| batch_normalization_937            -       (-1, 28, 28, 928)         0      1856     7.25           0            0 |\n",
      "| max_pooling2d_130                  -       (-1, 14, 14, 928)         0         0        0           0            0 |\n",
      "| activation_130                     -       (-1, 14, 14, 928)         0         0        0           ?            ? |\n",
      "| conv2d_110                         -       (-1, 14, 14, 288)         0    267264  1044.00           0     52383744 |\n",
      "| batch_normalization_938            -       (-1, 14, 14, 288)         0       576     2.25           0            0 |\n",
      "| quant_conv2d_653                   1        (-1, 14, 14, 64)    165888         0    20.25    32514048            0 |\n",
      "| concatenate_548                    -       (-1, 14, 14, 352)         0         0        0           ?            ? |\n",
      "| batch_normalization_939            -       (-1, 14, 14, 352)         0       704     2.75           0            0 |\n",
      "| quant_conv2d_654                   1        (-1, 14, 14, 64)    202752         0    24.75    39739392            0 |\n",
      "| concatenate_549                    -       (-1, 14, 14, 416)         0         0        0           ?            ? |\n",
      "| batch_normalization_940            -       (-1, 14, 14, 416)         0       832     3.25           0            0 |\n",
      "| quant_conv2d_655                   1        (-1, 14, 14, 64)    239616         0    29.25    46964736            0 |\n",
      "| concatenate_550                    -       (-1, 14, 14, 480)         0         0        0           ?            ? |\n",
      "| batch_normalization_941            -       (-1, 14, 14, 480)         0       960     3.75           0            0 |\n",
      "| quant_conv2d_656                   1        (-1, 14, 14, 64)    276480         0    33.75    54190080            0 |\n",
      "| concatenate_551                    -       (-1, 14, 14, 544)         0         0        0           ?            ? |\n",
      "| batch_normalization_942            -       (-1, 14, 14, 544)         0      1088     4.25           0            0 |\n",
      "| quant_conv2d_657                   1        (-1, 14, 14, 64)    313344         0    38.25    61415424            0 |\n",
      "| concatenate_552                    -       (-1, 14, 14, 608)         0         0        0           ?            ? |\n",
      "| batch_normalization_943            -       (-1, 14, 14, 608)         0      1216     4.75           0            0 |\n",
      "| quant_conv2d_658                   1        (-1, 14, 14, 64)    350208         0    42.75    68640768            0 |\n",
      "| concatenate_553                    -       (-1, 14, 14, 672)         0         0        0           ?            ? |\n",
      "| batch_normalization_944            -       (-1, 14, 14, 672)         0      1344     5.25           0            0 |\n",
      "| quant_conv2d_659                   1        (-1, 14, 14, 64)    387072         0    47.25    75866112            0 |\n",
      "| concatenate_554                    -       (-1, 14, 14, 736)         0         0        0           ?            ? |\n",
      "| batch_normalization_945            -       (-1, 14, 14, 736)         0      1472     5.75           0            0 |\n",
      "| quant_conv2d_660                   1        (-1, 14, 14, 64)    423936         0    51.75    83091456            0 |\n",
      "| concatenate_555                    -       (-1, 14, 14, 800)         0         0        0           ?            ? |\n",
      "| batch_normalization_946            -       (-1, 14, 14, 800)         0      1600     6.25           0            0 |\n",
      "| quant_conv2d_661                   1        (-1, 14, 14, 64)    460800         0    56.25    90316800            0 |\n",
      "| concatenate_556                    -       (-1, 14, 14, 864)         0         0        0           ?            ? |\n",
      "| batch_normalization_947            -       (-1, 14, 14, 864)         0      1728     6.75           0            0 |\n",
      "| quant_conv2d_662                   1        (-1, 14, 14, 64)    497664         0    60.75    97542144            0 |\n",
      "| concatenate_557                    -       (-1, 14, 14, 928)         0         0        0           ?            ? |\n",
      "| batch_normalization_948            -       (-1, 14, 14, 928)         0      1856     7.25           0            0 |\n",
      "| quant_conv2d_663                   1        (-1, 14, 14, 64)    534528         0    65.25   104767488            0 |\n",
      "| concatenate_558                    -       (-1, 14, 14, 992)         0         0        0           ?            ? |\n",
      "| batch_normalization_949            -       (-1, 14, 14, 992)         0      1984     7.75           0            0 |\n",
      "| quant_conv2d_664                   1        (-1, 14, 14, 64)    571392         0    69.75   111992832            0 |\n",
      "| concatenate_559                    -      (-1, 14, 14, 1056)         0         0        0           ?            ? |\n",
      "| batch_normalization_950            -      (-1, 14, 14, 1056)         0      2112     8.25           0            0 |\n",
      "| quant_conv2d_665                   1        (-1, 14, 14, 64)    608256         0    74.25   119218176            0 |\n",
      "| concatenate_560                    -      (-1, 14, 14, 1120)         0         0        0           ?            ? |\n",
      "| batch_normalization_951            -      (-1, 14, 14, 1120)         0      2240     8.75           0            0 |\n",
      "| quant_conv2d_666                   1        (-1, 14, 14, 64)    645120         0    78.75   126443520            0 |\n",
      "| concatenate_561                    -      (-1, 14, 14, 1184)         0         0        0           ?            ? |\n",
      "| batch_normalization_952            -      (-1, 14, 14, 1184)         0      2368     9.25           0            0 |\n",
      "| max_pooling2d_131                  -        (-1, 7, 7, 1184)         0         0        0           0            0 |\n",
      "| activation_131                     -        (-1, 7, 7, 1184)         0         0        0           ?            ? |\n",
      "| conv2d_111                         -         (-1, 7, 7, 288)         0    340992  1332.00           0     16708608 |\n",
      "| batch_normalization_953            -         (-1, 7, 7, 288)         0       576     2.25           0            0 |\n",
      "| quant_conv2d_667                   1          (-1, 7, 7, 64)    165888         0    20.25     8128512            0 |\n",
      "| concatenate_562                    -         (-1, 7, 7, 352)         0         0        0           ?            ? |\n",
      "| batch_normalization_954            -         (-1, 7, 7, 352)         0       704     2.75           0            0 |\n",
      "| quant_conv2d_668                   1          (-1, 7, 7, 64)    202752         0    24.75     9934848            0 |\n",
      "| concatenate_563                    -         (-1, 7, 7, 416)         0         0        0           ?            ? |\n",
      "| batch_normalization_955            -         (-1, 7, 7, 416)         0       832     3.25           0            0 |\n",
      "| quant_conv2d_669                   1          (-1, 7, 7, 64)    239616         0    29.25    11741184            0 |\n",
      "| concatenate_564                    -         (-1, 7, 7, 480)         0         0        0           ?            ? |\n",
      "| batch_normalization_956            -         (-1, 7, 7, 480)         0       960     3.75           0            0 |\n",
      "| quant_conv2d_670                   1          (-1, 7, 7, 64)    276480         0    33.75    13547520            0 |\n",
      "| concatenate_565                    -         (-1, 7, 7, 544)         0         0        0           ?            ? |\n",
      "| batch_normalization_957            -         (-1, 7, 7, 544)         0      1088     4.25           0            0 |\n",
      "| quant_conv2d_671                   1          (-1, 7, 7, 64)    313344         0    38.25    15353856            0 |\n",
      "| concatenate_566                    -         (-1, 7, 7, 608)         0         0        0           ?            ? |\n",
      "| batch_normalization_958            -         (-1, 7, 7, 608)         0      1216     4.75           0            0 |\n",
      "| quant_conv2d_672                   1          (-1, 7, 7, 64)    350208         0    42.75    17160192            0 |\n",
      "| concatenate_567                    -         (-1, 7, 7, 672)         0         0        0           ?            ? |\n",
      "| batch_normalization_959            -         (-1, 7, 7, 672)         0      1344     5.25           0            0 |\n",
      "| quant_conv2d_673                   1          (-1, 7, 7, 64)    387072         0    47.25    18966528            0 |\n",
      "| concatenate_568                    -         (-1, 7, 7, 736)         0         0        0           ?            ? |\n",
      "| batch_normalization_960            -         (-1, 7, 7, 736)         0      1472     5.75           0            0 |\n",
      "| quant_conv2d_674                   1          (-1, 7, 7, 64)    423936         0    51.75    20772864            0 |\n",
      "| concatenate_569                    -         (-1, 7, 7, 800)         0         0        0           ?            ? |\n",
      "| batch_normalization_961            -         (-1, 7, 7, 800)         0      1600     6.25           0            0 |\n",
      "| activation_132                     -         (-1, 7, 7, 800)         0         0        0           ?            ? |\n",
      "| max_pooling2d_132                  -         (-1, 1, 1, 800)         0         0        0           0            0 |\n",
      "| flatten_68                         -               (-1, 800)         0         0        0           0            0 |\n",
      "| dense_27                           -              (-1, 1000)         0    801000  3128.91           0       800000 |\n",
      "| activation_133                     -              (-1, 1000)         0         0        0           ?            ? |\n",
      "+--------------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                         12349440   1540072  7523.41  6430556160    244103424 |\n",
      "+--------------------------------------------------------------------------------------------------------------------+\n",
      "+DenseNet_E45 summary-------------------------+\n",
      "| Total params                      13.9 M    |\n",
      "| Trainable params                  13.8 M    |\n",
      "| Non-trainable params              49.7 k    |\n",
      "| Model size                        7.35 MiB  |\n",
      "| Model size (8-bit FP weights)     2.94 MiB  |\n",
      "| Float-32 Equivalent               52.98 MiB |\n",
      "| Compression Ratio of Memory       0.14      |\n",
      "| Number of MACs                    6.67 B    |\n",
      "| Ratio of MACs that are binarized  0.9634    |\n",
      "+---------------------------------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+QuickNet stats---------------------------------------------------------------------------------------------------+\n",
      "| Layer                     Input prec.             Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                 (bit)                           x 1       x 1     (kB)                          |\n",
      "+-----------------------------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d_675                    -  (-1, 112, 112, 16)         0       432     1.69           0      5419008 |\n",
      "| batch_normalization_984             -  (-1, 112, 112, 16)         0        32     0.12           0            0 |\n",
      "| activation_140                      -  (-1, 112, 112, 16)         0         0        0           ?            ? |\n",
      "| quant_depthwise_conv2d              -    (-1, 56, 56, 16)         0       144     0.56           0       451584 |\n",
      "| batch_normalization_985             -    (-1, 56, 56, 16)         0        32     0.12           0            0 |\n",
      "| quant_conv2d_676                    -    (-1, 56, 56, 64)         0      1024     4.00           0      3211264 |\n",
      "| batch_normalization_986             -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_677                    1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_987             -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_678                    1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_988             -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_679                    1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_989             -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_680                    1    (-1, 56, 56, 64)     36864         0     4.50   115605504            0 |\n",
      "| batch_normalization_990             -    (-1, 56, 56, 64)         0       128     0.50           0            0 |\n",
      "| activation_141                      -    (-1, 56, 56, 64)         0         0        0           ?            ? |\n",
      "| max_pooling2d_136                   -    (-1, 55, 55, 64)         0         0        0           0            0 |\n",
      "| depthwise_conv2d_6                  -    (-1, 28, 28, 64)         0       576     2.25           0       451584 |\n",
      "| quant_conv2d_681                    -   (-1, 28, 28, 128)         0      8192    32.00           0      6422528 |\n",
      "| batch_normalization_991             -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_682                    1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_992             -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_683                    1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_993             -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_684                    1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_994             -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| quant_conv2d_685                    1   (-1, 28, 28, 128)    147456         0    18.00   115605504            0 |\n",
      "| batch_normalization_995             -   (-1, 28, 28, 128)         0       256     1.00           0            0 |\n",
      "| activation_142                      -   (-1, 28, 28, 128)         0         0        0           ?            ? |\n",
      "| max_pooling2d_137                   -   (-1, 27, 27, 128)         0         0        0           0            0 |\n",
      "| depthwise_conv2d_7                  -   (-1, 14, 14, 128)         0      1152     4.50           0       225792 |\n",
      "| quant_conv2d_686                    -   (-1, 14, 14, 256)         0     32768   128.00           0      6422528 |\n",
      "| batch_normalization_996             -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_687                    1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_997             -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_688                    1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_998             -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_689                    1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_999             -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_690                    1   (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_1000            -   (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| activation_143                      -   (-1, 14, 14, 256)         0         0        0           ?            ? |\n",
      "| max_pooling2d_138                   -   (-1, 13, 13, 256)         0         0        0           0            0 |\n",
      "| depthwise_conv2d_8                  -     (-1, 7, 7, 256)         0      2304     9.00           0       112896 |\n",
      "| quant_conv2d_691                    -     (-1, 7, 7, 512)         0    131072   512.00           0      6422528 |\n",
      "| batch_normalization_1001            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_692                    1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1002            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_693                    1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1003            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_694                    1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1004            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_695                    1     (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1005            -     (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| activation_144                      -     (-1, 7, 7, 512)         0         0        0           ?            ? |\n",
      "| average_pooling2d_12                -     (-1, 1, 1, 512)         0         0        0           0            0 |\n",
      "| flatten_70                          -           (-1, 512)         0         0        0           0            0 |\n",
      "| quant_dense_15                      -          (-1, 1000)         0    513000  2003.91           0       512000 |\n",
      "| activation_145                      -          (-1, 1000)         0         0        0           ?            ? |\n",
      "+-----------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                      12533760    700328  4265.66  1849688064     29651712 |\n",
      "+-----------------------------------------------------------------------------------------------------------------+\n",
      "+QuickNet summary-----------------------------+\n",
      "| Total params                      13.2 M    |\n",
      "| Trainable params                  13.2 M    |\n",
      "| Non-trainable params              13.7 k    |\n",
      "| Model size                        4.17 MiB  |\n",
      "| Model size (8-bit FP weights)     2.16 MiB  |\n",
      "| Float-32 Equivalent               50.48 MiB |\n",
      "| Compression Ratio of Memory       0.08      |\n",
      "| Number of MACs                    1.88 B    |\n",
      "| Ratio of MACs that are binarized  0.9842    |\n",
      "+---------------------------------------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QKeras network successfully created\n",
      "Larq network successfully created\n",
      "+QuickNet Small stats--------------------------------------------------------------------------------------------+\n",
      "| Layer                     Input prec.            Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
      "|                                 (bit)                          x 1       x 1     (kB)                          |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d_696                    -  (-1, 112, 112, 8)         0       216     0.84           0      2709504 |\n",
      "| batch_normalization_1028            -  (-1, 112, 112, 8)         0        16     0.06           0            0 |\n",
      "| activation_152                      -  (-1, 112, 112, 8)         0         0        0           ?            ? |\n",
      "| quant_depthwise_conv2d_1            -    (-1, 56, 56, 8)         0        72     0.28           0       225792 |\n",
      "| batch_normalization_1029            -    (-1, 56, 56, 8)         0        16     0.06           0            0 |\n",
      "| quant_conv2d_697                    -   (-1, 56, 56, 32)         0       256     1.00           0       802816 |\n",
      "| batch_normalization_1030            -   (-1, 56, 56, 32)         0        64     0.25           0            0 |\n",
      "| quant_conv2d_698                    1   (-1, 56, 56, 32)      9216         0     1.12    28901376            0 |\n",
      "| batch_normalization_1031            -   (-1, 56, 56, 32)         0        64     0.25           0            0 |\n",
      "| quant_conv2d_699                    1   (-1, 56, 56, 32)      9216         0     1.12    28901376            0 |\n",
      "| batch_normalization_1032            -   (-1, 56, 56, 32)         0        64     0.25           0            0 |\n",
      "| quant_conv2d_700                    1   (-1, 56, 56, 32)      9216         0     1.12    28901376            0 |\n",
      "| batch_normalization_1033            -   (-1, 56, 56, 32)         0        64     0.25           0            0 |\n",
      "| quant_conv2d_701                    1   (-1, 56, 56, 32)      9216         0     1.12    28901376            0 |\n",
      "| batch_normalization_1034            -   (-1, 56, 56, 32)         0        64     0.25           0            0 |\n",
      "| activation_153                      -   (-1, 56, 56, 32)         0         0        0           ?            ? |\n",
      "| max_pooling2d_142                   -   (-1, 55, 55, 32)         0         0        0           0            0 |\n",
      "| depthwise_conv2d_12                 -   (-1, 28, 28, 32)         0       288     1.12           0       225792 |\n",
      "| quant_conv2d_702                    -   (-1, 28, 28, 64)         0      2048     8.00           0      1605632 |\n",
      "| batch_normalization_1035            -   (-1, 28, 28, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_703                    1   (-1, 28, 28, 64)     36864         0     4.50    28901376            0 |\n",
      "| batch_normalization_1036            -   (-1, 28, 28, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_704                    1   (-1, 28, 28, 64)     36864         0     4.50    28901376            0 |\n",
      "| batch_normalization_1037            -   (-1, 28, 28, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_705                    1   (-1, 28, 28, 64)     36864         0     4.50    28901376            0 |\n",
      "| batch_normalization_1038            -   (-1, 28, 28, 64)         0       128     0.50           0            0 |\n",
      "| quant_conv2d_706                    1   (-1, 28, 28, 64)     36864         0     4.50    28901376            0 |\n",
      "| batch_normalization_1039            -   (-1, 28, 28, 64)         0       128     0.50           0            0 |\n",
      "| activation_154                      -   (-1, 28, 28, 64)         0         0        0           ?            ? |\n",
      "| max_pooling2d_143                   -   (-1, 27, 27, 64)         0         0        0           0            0 |\n",
      "| depthwise_conv2d_13                 -   (-1, 14, 14, 64)         0       576     2.25           0       112896 |\n",
      "| quant_conv2d_707                    -  (-1, 14, 14, 256)         0     16384    64.00           0      3211264 |\n",
      "| batch_normalization_1040            -  (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_708                    1  (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_1041            -  (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_709                    1  (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_1042            -  (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_710                    1  (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_1043            -  (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| quant_conv2d_711                    1  (-1, 14, 14, 256)    589824         0    72.00   115605504            0 |\n",
      "| batch_normalization_1044            -  (-1, 14, 14, 256)         0       512     2.00           0            0 |\n",
      "| activation_155                      -  (-1, 14, 14, 256)         0         0        0           ?            ? |\n",
      "| max_pooling2d_144                   -  (-1, 13, 13, 256)         0         0        0           0            0 |\n",
      "| depthwise_conv2d_14                 -    (-1, 7, 7, 256)         0      2304     9.00           0       112896 |\n",
      "| quant_conv2d_712                    -    (-1, 7, 7, 512)         0    131072   512.00           0      6422528 |\n",
      "| batch_normalization_1045            -    (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_713                    1    (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1046            -    (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_714                    1    (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1047            -    (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_715                    1    (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1048            -    (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| quant_conv2d_716                    1    (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
      "| batch_normalization_1049            -    (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
      "| activation_156                      -    (-1, 7, 7, 512)         0         0        0           ?            ? |\n",
      "| average_pooling2d_14                -    (-1, 1, 1, 512)         0         0        0           0            0 |\n",
      "| flatten_72                          -          (-1, 512)         0         0        0           0            0 |\n",
      "| quant_dense_16                      -         (-1, 1000)         0    513000  2003.91           0       512000 |\n",
      "| activation_157                      -         (-1, 1000)         0         0        0           ?            ? |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "| Total                                                     11980800    674888  4098.78  1156055040     15941120 |\n",
      "+----------------------------------------------------------------------------------------------------------------+\n",
      "+QuickNet Small summary-----------------------+\n",
      "| Total params                      12.7 M    |\n",
      "| Trainable params                  12.6 M    |\n",
      "| Non-trainable params              11.8 k    |\n",
      "| Model size                        4.00 MiB  |\n",
      "| Model size (8-bit FP weights)     2.07 MiB  |\n",
      "| Float-32 Equivalent               48.28 MiB |\n",
      "| Compression Ratio of Memory       0.08      |\n",
      "| Number of MACs                    1.17 B    |\n",
      "| Ratio of MACs that are binarized  0.9864    |\n",
      "+---------------------------------------------+\n",
      "\n",
      "QKeras network successfully created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larq network successfully created\n",
      "+QuickNet Large stats------------------------------------------------------------------------+\n",
      "| Layer                     Input prec.             Outputs  # 32-bit    Memory  32-bit MACs |\n",
      "|                                 (bit)                           x 1      (kB)              |\n",
      "+--------------------------------------------------------------------------------------------+\n",
      "| quant_conv2d_719                    -  (-1, 112, 112, 16)       432      1.69      5419008 |\n",
      "| batch_normalization_1088            -  (-1, 112, 112, 16)        32      0.12            0 |\n",
      "| activation_164                      -  (-1, 112, 112, 16)         0         0            ? |\n",
      "| quant_depthwise_conv2d_3            -    (-1, 56, 56, 16)       144      0.56       451584 |\n",
      "| batch_normalization_1089            -    (-1, 56, 56, 16)        32      0.12            0 |\n",
      "| quant_conv2d_720                    -    (-1, 56, 56, 64)      1024      4.00      3211264 |\n",
      "| batch_normalization_1090            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| q_activation_195                    -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| q_conv2d_203                        -    (-1, 56, 56, 64)     36864    144.00    115605504 |\n",
      "| batch_normalization_1091            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| q_activation_196                    -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| q_conv2d_204                        -    (-1, 56, 56, 64)     36864    144.00    115605504 |\n",
      "| batch_normalization_1092            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| q_activation_197                    -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| q_conv2d_205                        -    (-1, 56, 56, 64)     36864    144.00    115605504 |\n",
      "| batch_normalization_1093            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| q_activation_198                    -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| q_conv2d_206                        -    (-1, 56, 56, 64)     36864    144.00    115605504 |\n",
      "| batch_normalization_1094            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| q_activation_199                    -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| q_conv2d_207                        -    (-1, 56, 56, 64)     36864    144.00    115605504 |\n",
      "| batch_normalization_1095            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| q_activation_200                    -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| q_conv2d_208                        -    (-1, 56, 56, 64)     36864    144.00    115605504 |\n",
      "| batch_normalization_1096            -    (-1, 56, 56, 64)       128      0.50            0 |\n",
      "| activation_165                      -    (-1, 56, 56, 64)         0         0            ? |\n",
      "| max_pooling2d_148                   -    (-1, 55, 55, 64)         0         0            0 |\n",
      "| depthwise_conv2d_18                 -    (-1, 28, 28, 64)       576      2.25       451584 |\n",
      "| q_conv2d_209                        -   (-1, 28, 28, 128)      8192     32.00      6422528 |\n",
      "| batch_normalization_1097            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_201                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_210                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1098            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_202                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_211                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1099            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_203                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_212                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1100            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_204                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_213                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1101            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_205                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_214                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1102            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_206                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_215                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1103            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_207                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_216                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1104            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| q_activation_208                    -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| q_conv2d_217                        -   (-1, 28, 28, 128)    147456    576.00    115605504 |\n",
      "| batch_normalization_1105            -   (-1, 28, 28, 128)       256      1.00            0 |\n",
      "| activation_166                      -   (-1, 28, 28, 128)         0         0            ? |\n",
      "| max_pooling2d_149                   -   (-1, 27, 27, 128)         0         0            0 |\n",
      "| depthwise_conv2d_19                 -   (-1, 14, 14, 128)      1152      4.50       225792 |\n",
      "| q_conv2d_218                        -   (-1, 14, 14, 256)     32768    128.00      6422528 |\n",
      "| batch_normalization_1106            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_209                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_219                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1107            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_210                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_220                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1108            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_211                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_221                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1109            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_212                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_222                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1110            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_213                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_223                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1111            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_214                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_224                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1112            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_215                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_225                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1113            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_216                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_226                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1114            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_217                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_227                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1115            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_218                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_228                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1116            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_219                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_229                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1117            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| q_activation_220                    -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| q_conv2d_230                        -   (-1, 14, 14, 256)    589824   2304.00    115605504 |\n",
      "| batch_normalization_1118            -   (-1, 14, 14, 256)       512      2.00            0 |\n",
      "| activation_167                      -   (-1, 14, 14, 256)         0         0            ? |\n",
      "| max_pooling2d_150                   -   (-1, 13, 13, 256)         0         0            0 |\n",
      "| depthwise_conv2d_20                 -     (-1, 7, 7, 256)      2304      9.00       112896 |\n",
      "| q_conv2d_231                        -     (-1, 7, 7, 512)    131072    512.00      6422528 |\n",
      "| batch_normalization_1119            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| q_activation_221                    -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| q_conv2d_232                        -     (-1, 7, 7, 512)   2359296   9216.00    115605504 |\n",
      "| batch_normalization_1120            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| q_activation_222                    -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| q_conv2d_233                        -     (-1, 7, 7, 512)   2359296   9216.00    115605504 |\n",
      "| batch_normalization_1121            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| q_activation_223                    -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| q_conv2d_234                        -     (-1, 7, 7, 512)   2359296   9216.00    115605504 |\n",
      "| batch_normalization_1122            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| q_activation_224                    -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| q_conv2d_235                        -     (-1, 7, 7, 512)   2359296   9216.00    115605504 |\n",
      "| batch_normalization_1123            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| q_activation_225                    -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| q_conv2d_236                        -     (-1, 7, 7, 512)   2359296   9216.00    115605504 |\n",
      "| batch_normalization_1124            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| q_activation_226                    -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| q_conv2d_237                        -     (-1, 7, 7, 512)   2359296   9216.00    115605504 |\n",
      "| batch_normalization_1125            -     (-1, 7, 7, 512)      1024      4.00            0 |\n",
      "| activation_168                      -     (-1, 7, 7, 512)         0         0            ? |\n",
      "| average_pooling2d_16                -     (-1, 1, 1, 512)         0         0            0 |\n",
      "| flatten_74                          -           (-1, 512)         0         0            0 |\n",
      "| quant_dense_18                      -          (-1, 1000)    513000   2003.91       512000 |\n",
      "| activation_169                      -          (-1, 1000)         0         0            ? |\n",
      "+--------------------------------------------------------------------------------------------+\n",
      "| Total                                                      23342248  91180.66   3729027840 |\n",
      "+--------------------------------------------------------------------------------------------+\n",
      "+QuickNet Large summary--------------------+\n",
      "| Total params                   23.3 M    |\n",
      "| Trainable params               23.3 M    |\n",
      "| Non-trainable params           21.1 k    |\n",
      "| Model size                     89.04 MiB |\n",
      "| Model size (8-bit FP weights)  22.26 MiB |\n",
      "| Float-32 Equivalent            89.04 MiB |\n",
      "| Compression Ratio of Memory    1.00      |\n",
      "| Number of MACs                 3.73 B    |\n",
      "+------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "network = alexnet.AlexNet()\n",
    "_, model = network.build()\n",
    "model._name = \"AlexNet\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = birealnet.BirealNet()\n",
    "_, model = network.build()\n",
    "model._name = \"BiRealNet\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = binary_densenet.DenseNet(28)\n",
    "_, model = network.build()\n",
    "model._name = \"DenseNet_E28\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = binary_densenet.DenseNet(37)\n",
    "_, model = network.build()\n",
    "model._name = \"DenseNet_E37\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = binary_densenet.DenseNet(45)\n",
    "_, model = network.build()\n",
    "model._name = \"DenseNet_E45\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = binary_densenet37_dilated.DenseNetE37Dilated()\n",
    "_, model = network.build()\n",
    "model._name = \"DenseNet_E37 Dilated\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = quicknet.QuickNet(\"\")\n",
    "_, model = network.build()\n",
    "model._name = \"QuickNet\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = quicknet.QuickNet(\"small\")\n",
    "_, model = network.build()\n",
    "model._name = \"QuickNet Small\"\n",
    "lq.models.summary(model)\n",
    "\n",
    "network = quicknet.QuickNet(\"large\")\n",
    "_, model = network.build()\n",
    "model._name = \"QuickNet Large\"\n",
    "lq.models.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
